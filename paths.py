


yangjie_rich_pretrain_unigram_path = '../embedding/gigaword_chn.all.a2b.uni.ite50.vec'
yangjie_rich_pretrain_bigram_path = '../embedding/gigaword_chn.all.a2b.bi.ite50.vec'
yangjie_rich_pretrain_word_path = '../embedding/ctb.50d.vec'
yangjie_rich_pretrain_char_and_word_path = '../embedding/yangjie_word_char_mix.txt'
lk_word_path = '../embedding/sgns.merge.word'
# lk_word_path_2 = '/remote-home/xnli/data/pretrain/chinese/sgns.merge.word_2'



ontonote4ner_cn_path = '../dataset/NER_OntoNote4'
msra_ner_cn_path = '../dataset/NER_MSRA'
resume_ner_path = '../dataset/NER_Resume'
weibo_ner_path = '../dataset/NER_Weibo'

databaker_tn_path = '../dataset/processed/shuffled_BMESO'


# yangjie_rich_pretrain_unigram_path = '{}/gigaword_chn.all.a2b.uni.ite50.vec'
# yangjie_rich_pretrain_bigram_path = '{}/gigaword_chn.all.a2b.bi.ite50.vec'
# yangjie_rich_pretrain_word_path = '{}/ctb.50d.vec'
#
# # this path is for the output of preprocessing
# yangjie_rich_pretrain_char_and_word_path = '{}/yangjie_word_char_mix.txt'
#
#
#
# ontonote4ner_cn_path = '{}/OntoNote4NER'
# msra_ner_cn_path = '{}/MSRANER'
# resume_ner_path = '{}/ResumeNER'
# weibo_ner_path = '{}/WeiboNER'